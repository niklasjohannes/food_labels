---
title: "Data Analysis Report Study 1"
author: "Niklas Johannes"
date: "25/11/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      message = FALSE, 
                      warning = FALSE,
                      cache = TRUE)
```

This file explains all data processing and analysis steps for Study 1 of [Project Title].
The RProject has a private library in order to make all steps computationally reproducible.
I use the `renv` package for this.
That means you will need to install the package and run the `renv::restore` command, see instructions [here](https://github.com/rstudio/renv).
```{r load_libraries}
# pacman makes it easier to load and install packages
if (!requireNamespace("pacman"))
  install.packages("pacman")

library(pacman)

# load packages
p_load(
  here,
  janitor,
  pastecs,
  betareg,
  car,
  lattice,
  cowplot,
  tidyverse
)

# set seed
set.seed(42)

# set theme
theme_set(theme_cowplot())
```

```{r custom_functions}
### FUNCTION 1 ###
# little function that describes and visualizes variables, either for repeated-measures or trait-like
describe_visualize <- 
  function(df, 
           variable, 
           repeated_measure = FALSE,
           want_summary = FALSE){
    
    variable <- enquo(variable)
    
    # specifies whether the variable we want to plot is a trait-like or repeated measure
    if (repeated_measure == FALSE){
      df <-
        df %>%
        group_by(food) %>%
        slice(1) %>% 
        ungroup()
    } else {
      df <-
        df
    }
    
    # descriptive stats
    sum_stats <-
      df %>% 
      pull(!! variable) %>% 
      stat.desc()
    
    # plot
    plot <-
      ggplot(df, aes(x = !! variable)) +
        geom_density(color = "darkgrey", fill = "darkgrey") +
        geom_point(aes(x = !! variable, y = 0))
    
    # return the two (if both are wanted)
    if(want_summary == TRUE){
      return(list(knitr::kable(sum_stats), plot))
    } else{
      return(plot)
    }
  }

### FUNCTION 2 ###
# function to produce violin plots for a variable for each food type
three_violins <-
  function(
    df,
    variable
  ){
    
    variable <- enquo(variable)
    
    df <-
      df %>% 
      group_by(food) %>% 
      slice(1) %>% 
      ungroup()
    
    ggplot(
      df,
      aes(
        x = food_type,
        y = !! variable,
        color = food_type,
        fill = food_type
      )
    ) +
      geom_violin() +
      scale_color_brewer(palette = "Dark2") +
      scale_fill_brewer(palette = "Dark2")
  }

### FUNCTION 3###
# provides summary statistics for a variable for each food type
summary_stats <-
  function(
    df,
    variable
  ){
    variable <- enquo(variable)
    
    summary_stats <-
      df %>%
      group_by(food_type) %>%
      summarize(mean = mean(!! variable),
                sd = sd(!! variable))
    
    summary_stats
  }

### FUNCTION 4 ###
# applies the betareg transformation
betareg_transformation <-
  function(
    value
  ) {
    n <- length(unique(analysis_file$food))
    
    value <-
      (value * (n - 1) + 0.5) / n
  }


### FUNCTION 5 ###
# arranges cook's distance from highest to lowest
arrange_cook <-
  function(outliers, grouping_factor){
    cooks.distance(outliers) %>% 
      as_tibble(rownames = as.character(grouping_factor)) %>%
      rename(cooks_distance = value) %>% 
      arrange(desc(cooks_distance)) %>% 
      head()
  }
```

# 1. Load data and wrangle data
First, we load the data.
For a codebook, see the [enter file name] file.
```{r load_data}
raw_data <- read_csv(
  here("data", "study1", "raw_data.csv")
  )
```

The variable names aren't in a nice format.
Notably, they all contain `_all_items_final` at the end and are in all upper case.
I will first remove the `_all_items_final` part from the variable names and then use the `janitor` package to get nicer variable names.
```{r clean_names}
# use a working file from now on
working_file <- raw_data

# remove variable name part
names(working_file) <-
  names(working_file) %>% 
  str_remove(., "_all_items_final")

# get variable names in snake case
working_file <- 
  clean_names(working_file)

# inspect data
glimpse(working_file)
```

Next, I add a food type category based on the subject number (`subjectnr` indicates the food ID):

* 1-80: vegan
* 81-160: vegetarian
* 161-240: meat-based
```{r add_food_type}
working_file <-
  working_file %>% 
  mutate(
    food_type = case_when(
      subjectnr %in% 1:80 ~ "vegan",
      subjectnr %in% 81:160 ~ "vegetarian",
      subjectnr %in% 161:240 ~ "meat_based"
    )
  ) %>% 
  rename( # give more sensible name for food ID
    "food_id" = "subjectnr"
  )
```

At this point, we also don't have the actual food names in the data set.
Although we don't necessarily need them in the analysis, I'll add them for completeness' sake.

The food label data set is in the long format, meaning I first need to get unique food names, then add them to working file.
```{r add_food_names}
# read the file with food names and features
food_labels <-
  read_csv(
    here("data", "study1", "food_labels.csv")
  )

# add food names to raw_data
working_file <-
  working_file %>% 
    add_column(
      food = unique(food_labels$food)
    ) %>% # reorder variable names
  select(food_id, food, everything())
```

Next, I create the total number of features produced per food item and the proportion of features for each item.
```{r total_features}
# add total features per item and remove ambigous and nonwords
working_file <-
  working_file %>%
  select(-ambiguous, -nonword) %>% 
  mutate(
    total = rowSums(select(., production:neg_coping))
  )

# add proportion of each feature in relation to total number of features
total_proportions <-
  working_file %>% 
  mutate_at(
    vars(production:neg_coping),
    list(~ . / total)
  )

# add an identifier of that variable name
names(total_proportions)[3:45] <-
  names(total_proportions %>% 
          select(production:neg_coping)) %>% 
  str_replace(., "$", "_proportion")

# add those proportion variables to working file
working_file <-
  left_join(
    working_file,
    total_proportions
  )
```

I repeat these two steps for the three main categories: consumption situations, non-consumption situations, and situation-independent situations.
```{r per_category_features}
# get total number of features per category
working_file <-
  working_file %>% 
    mutate(
      consumption_total = rowSums(select(., taste_flavor:neg_coping)),
      non_consumption_total = rowSums(select(., production:prep_stor, cult_embed)),
      situation_independent_total = rowSums(select(., ingred_cont:long_ter_neg, overall_pos_eval:linguistic))
    )

# now proportion of features in that category
category_proportions <-
  working_file %>% 
    mutate_at(
      vars(
        consumption_total,
        non_consumption_total,
        situation_independent_total
      ),
      list(~ . / total)
    ) %>% select(food_id, consumption_total:situation_independent_total)

# add an identifier for those variables
names(category_proportions)[2:4] <-
  names(category_proportions %>% 
  select(-food_id)) %>% 
  str_replace(., "total", "proportion")

# add those proportion variables to working file
working_file <-
  left_join(
    working_file,
    category_proportions,
    by = c("food_id")
  )
```

Last, I do the same for the different sub-categories of consumption situations: sensory & reward, immediate positive consequences, immediate negative consequences, and contextual features.
```{r per_sub_category_features}
# get total number of features per sub-category
working_file <-
  working_file %>% 
    mutate(
      sensory_total = rowSums(select(., taste_flavor:action)),
      positive_total = rowSums(select(.,
                                      pos_conform_goals,
                                      pos_social_goals,
                                      pos_bodily_conseq:pos_coping)),
      negative_total = rowSums(select(.,
                                neg_conform_goals,
                                neg_social_goals,
                                neg_bodily_conseq:neg_coping)),
      contextual_total = rowSums(select(., cont_bodily:cont_consumable))
    )

# now proportion of features in that category
sub_category_proportions <-
  working_file %>% 
    mutate_at(
      vars(sensory_total:contextual_total),
      list(~ . / total)
    ) %>% select(food_id, sensory_total:contextual_total)

# add an identifier for those variables
names(sub_category_proportions)[2:5] <-
  names(sub_category_proportions %>% 
  select(-food_id)) %>% 
  str_replace(., "total", "proportion")

# add those proportion variables to working file
working_file <-
  left_join(
    working_file,
    sub_category_proportions,
    by = c("food_id")
  )
```

Okay, now the file contains all information, but is not following tidy data conventions.
```{r tidy_data}
# first add an identifier to the feature count variables
names(working_file)[3:45] <-
  names(working_file %>% 
          select(production:neg_coping)) %>% 
  str_replace(., "$", "_count")

# then pivot to longer
working_file <-
  working_file %>% 
    pivot_longer(
      cols = c(production_count:neg_coping_count, production_proportion:neg_coping_proportion),
      names_to = c("feature", ".value"), # period to tell tidyr that that's where the value is
      names_sep = "_(?!.*_)", # looks for last underscore as the separator (which separates count and proportion)
      values_drop_na = TRUE
    ) %>% 
    select( #reorder variables
      food_id,
      food,
      food_type,
      feature:proportion,
      total,
      consumption_total:situation_independent_total,
      sensory_total:contextual_total,
      consumption_proportion:situation_independent_proportion,
      sensory_proportion:contextual_proportion
    ) %>% # assign proper variable types
    mutate_at(
      vars(contains("food"), feature),
      list(~ as.factor(.))
    )

# summary stats
working_file %>% 
  group_by(food) %>% 
  slice(1) %>% 
  ungroup() %>% 
  summarize_at(
    vars(
      sensory_proportion,
      positive_proportion,
      contextual_proportion
    ),
    list(mean = mean, median = median, sd = sd)
  )
```

# 2. Describe and visualize
Next, I visualize the different variables.
I'll start with the total number of features overall and per food.
Overall, it looks skewed with a long left tail, but without a really clear visual outlier.
```{r visualize_totals_per_food}
# number of features per food and feature type
ggplot(
  data = working_file,
  aes(
    x = reorder(food, count),
    y = count
  )
) +
  geom_bar(
    stat = "identity"
  )

# distribution of total features
ggplot(data = working_file %>% group_by(food) %>% slice(1),
       aes(
         x = total
       )) + 
  geom_density(color = "darkgrey", 
               fill = "darkgrey")

# summary stats
working_file %>%
  group_by(food) %>% 
  slice(1) %>% 
  ungroup() %>% 
  pull(total) %>% 
  stat.desc()
```

Next, I'll do the same with the proportions proportions of consumption situtation features.
Looks pretty much like a binomial or beta distribution.
One food didn't have any of those features in its labels.
```{r visualize_consumption_features}
describe_visualize(
  working_file,
  consumption_proportion,
  FALSE,
  TRUE
)
```

Similar picture for non-consupmtion situations, but with more mass toward the middle, reflected in higher mean.
```{r visualize_non_consumption_features}
describe_visualize(
  working_file,
  non_consumption_proportion,
  FALSE,
  TRUE
)
```

Situation-independent features have a different distribution with a strong left skew.
```{r visualize_independent_features}
describe_visualize(
  working_file,
  situation_independent_proportion,
  FALSE,
  TRUE
)
```

Last, I want to look at the three sub-categories of consumption features (negative immediate consequences didn't have any features, which is why I leave it out from now on).
```{r visualize_sub_features}
working_file %>% 
  # only select foods and the four sub-categories
  select(
    food_id,
    food,
    sensory_proportion,
    positive_proportion,
    contextual_proportion
  ) %>% 
  group_by(food) %>% 
  slice(1) %>% 
  ungroup() %>% 
  # turn into long format for faceting later
  pivot_longer(
    cols = c(-food_id, -food),
    names_to = c("feature_type", ".value"),
    names_sep = "_"
  ) %>% 
  ggplot(
    aes(x = proportion)
  ) +
  geom_density(color = "darkgrey", fill = "darkgrey") + 
  facet_wrap(~ feature_type)
```

Now per food type.
```{r visualize_totals_per_food_type}
three_violins(working_file, total)
summary_stats(working_file, total)
```

Alright, next I visualize the three main feature categories by food category, starting with consumption features.
```{r consumption_by_food_type}
three_violins(working_file, consumption_proportion)
summary_stats(working_file, consumption_proportion)
```

Next non-consumption features.
```{r non_consumption_by_food_type}
three_violins(working_file, non_consumption_proportion)
summary_stats(working_file, non_consumption_proportion)
```

Followed by situation-independent features.
```{r independent_by_food_type}
three_violins(working_file, situation_independent_proportion)
summary_stats(working_file, situation_independent_proportion)
```

The same for the four sub-categories, starting with sensory and action features.
```{r sensory_by_food_type}
three_violins(working_file, sensory_proportion)
summary_stats(working_file, sensory_proportion)
```

Next: Positive immediate consequences.
```{r positive_by_food_type}
three_violins(working_file, positive_proportion)
summary_stats(working_file, positive_proportion)
```

Contexutal features.
```{r contextual_by_food_type}
three_violins(working_file, contextual_proportion)
summary_stats(working_file, contextual_proportion)
```

# 3. Analysis

## 3.1 Confirmatory

Next, I see whether there are differences between the food categories on the proportions of features.
We had one hypothesis: Meat-based foods will have more sensory and action features than vegan or vegetarian foods.

First: an analysis file that only contains one line per food.
```{r analysis_file}
analysis_file <-
  working_file %>% 
  group_by(food) %>% 
  slice(1) %>% 
  ungroup() %>% 
  select(-feature) %>% 
  arrange(food_id)
```

We are analyzing proportions, meaning that a general linear model assuming a Gaussian distribution will most likely lead to biased effects. 
However, inspecting the proportions shows that most of them are following a binomial or beta distribution.

Usually, I would rely on a binomial linear model, but in this case I believe a beta regression model is more appropriate.
These models are used when we won't know before-hand how many total "trials" (aka total number of features for each food) there are.
For this, I use the `betareg` package.

Note that the `betareg` command assumes that all observations are between 0 and 1
In my case, many are exactly 0.
The authors [suggest](https://cran.r-project.org/web/packages/betareg/vignettes/betareg.pdf) to apply a transformation in this case.

The model diagnostics are relatively poor.
I will run the same analysis as a binomial model and compare.
```{r sensory_model_all}
# apply transformation function
analysis_file <-
  analysis_file %>%
  mutate(
    sensory_proportion_t = unlist(map(sensory_proportion, betareg_transformation))
  )

# set contrasts
options(contrasts = c("contr.treatment", "contr.poly"))

# check contrasts
contrasts(analysis_file$food_type)

# run analysis
sensory_model <-
  betareg(
    sensory_proportion_t ~
      food_type,
    analysis_file
  )

# summary
summary(sensory_model)

# inspect model
plot(sensory_model)

# residuals
densityplot(resid(sensory_model, scaled = TRUE))

# qqplot
car::qqPlot(resid(sensory_model, scaled = TRUE))

# check for formal outliers
arrange_cook(sensory_model, "food_id")
```


I run an additional binomial model, which might be better suited to deal with the data distribution.
The differences are significant, and the model diagnostics look much better, particularly the qq-plot.
I'd say we can trust the effects.

I'll use binomial models from here on.
Food `12` stands out in comparison to the rest, so I'll see whether the exclusion of this data point changes the results later.
```{r sensory_binomial}
# binomial
sensory_model_bi <-
  glm(
    cbind(sensory_total, total-sensory_total) ~
      food_type,
    data = analysis_file,
    family = binomial(logit)
  )

# summary
summary(sensory_model_bi)

# model diagnostics
plot(sensory_model_bi)

# residuals
densityplot(resid(sensory_model_bi, scaled = TRUE))

# check formal outliers
arrange_cook(sensory_model_bi, "food_id")
```

But first I'll run a model excluding meat-based foods to see whether the difference between vegan and vegetarian is significant.
It is not.
```{r sensory_model_no_meat}
# binomial
sensory_model_bi2 <-
  glm(
    cbind(sensory_total, total-sensory_total) ~
      food_type,
    data = analysis_file %>% filter(food_type != "meat_based"),
    family = binomial(logit)
  )

# summary
summary(sensory_model_bi2)

# model diagnostics
plot(sensory_model_bi2)

# residuals
densityplot(resid(sensory_model_bi2, scaled = TRUE))

# check formal outliers
arrange_cook(sensory_model_bi2, "food_id")

# effect size
sos::findFn(sensory_model_bi)
```

## 3.2 Exploratory

### 3.2.1 Sensory
First, I want to make sure the difference is indeed robust to the exclusion of outliers.
I'll exclude the three potentially influential cases.

The differences remain significant.
```{r sensory_model_no_outliers}
# binomial
sensory_model_bi_no_outliers <-
  glm(
    cbind(sensory_total, total-sensory_total) ~
      food_type,
    data = analysis_file %>% 
      filter(!food_id %in% c("12")),
    family = binomial(logit)
  )

# summary
summary(sensory_model_bi_no_outliers)
```

### 3.2.2 Consumption
Next, I'd like to explore whether there are any differences between food types on the three main situation categories.
Just like above, I'll start with consumption features.

The model fit is good.
There's a significant difference between meat-based and vegetarian foods, but not between meat-based an vegan.

Again, food `12` shows up as an outlier. 
I expected food `199`, which has 100% consumption features, to show up, but it doesn't.
I'll exclude both in the robustness check just to make sure the difference is not driven by model outlier or raw data outlier.
```{r consumption_binomial}
# binomial
consumption_model_bi <-
  glm(
    cbind(consumption_total, total-consumption_total) ~
      food_type,
    data = analysis_file,
    family = binomial(logit)
  )

# summary
summary(consumption_model_bi)

# model diagnostics
plot(consumption_model_bi)

# residuals
densityplot(resid(consumption_model_bi, scaled = TRUE))

# check formal outliers
arrange_cook(consumption_model_bi, "food_id")
```

Run a model excluding meat-based foods to see whether the difference between vegan and vegetarian is significant.
It is.
```{r consumption_model_no_meat}
# binomial
consumption_model_bi2 <-
  glm(
    cbind(consumption_total, total-consumption_total) ~
      food_type,
    data = analysis_file %>% filter(food_type != "meat_based"),
    family = binomial(logit)
  )

# summary
summary(consumption_model_bi2)

# model diagnostics
plot(consumption_model_bi2)

# residuals
densityplot(resid(consumption_model_bi2, scaled = TRUE))

# check formal outliers
arrange_cook(consumption_model_bi2, "food_id")
```

Now I check whether the effects in those two models are robust to outlier exclusion.
They are.
```{r consumption_model_no_outliers}
# binomial
consumption_model_bi_no_outliers <-
  glm(
    cbind(consumption_total, total-consumption_total) ~
      food_type,
    data = analysis_file %>% 
      filter(!food_id %in% c("12", "199")),
    family = binomial(logit)
  )

# summary
summary(consumption_model_bi_no_outliers)

# binomial
consumption_model_bi2_no_outliers <-
  glm(
    cbind(consumption_total, total-consumption_total) ~
      food_type,
    data = analysis_file %>% 
      filter(!food_id %in% c("12")) %>% 
      filter(food_type != "meat_based"),
    family = binomial(logit)
  )

# summary
summary(consumption_model_bi2_no_outliers)
```

### 3.2.3 Non-consumption

I'll continue with non-consumption features.

The model fit is good.
There's a significant difference between meat-based and vegan foods, but not between meat-based an vegetarian, which mirrors the results for consumption features.

Foods `150`, `9`, and `180` could potentially be influential, so I'll remove them in a robustness check.
```{r non_consumption_binomial}
# binomial
non_consumption_model_bi <-
  glm(
    cbind(non_consumption_total, total-non_consumption_total) ~
      food_type,
    data = analysis_file,
    family = binomial(logit)
  )

# summary
summary(non_consumption_model_bi)

# model diagnostics
plot(non_consumption_model_bi)

# residuals
densityplot(resid(non_consumption_model_bi, scaled = TRUE))

# check formal outliers
arrange_cook(non_consumption_model_bi, "food_id")
```

Run a model excluding meat-based foods to see whether the difference between vegan and vegetarian is significant.
It is.

Foods `150` and `9` agains stick out.
```{r non_consumption_model_no_meat}
# binomial
non_consumption_model_bi2 <-
  glm(
    cbind(non_consumption_total, total-non_consumption_total) ~
      food_type,
    data = analysis_file %>% filter(food_type != "meat_based"),
    family = binomial(logit)
  )

# summary
summary(non_consumption_model_bi2)

# model diagnostics
plot(non_consumption_model_bi2)

# residuals
densityplot(resid(non_consumption_model_bi2, scaled = TRUE))

# check formal outliers
arrange_cook(non_consumption_model_bi2, "food_id")
```

Now I check whether the effects in those two models are robust to outlier exclusion.
They are.
```{r non_non_consumption_model_no_outliers}
# binomial
non_consumption_model_bi_no_outliers <-
  glm(
    cbind(non_consumption_total, total-non_consumption_total) ~
      food_type,
    data = analysis_file %>% 
      filter(!food_id %in% c("150", "9", "180")),
    family = binomial(logit)
  )

# summary
summary(non_consumption_model_bi_no_outliers)

# binomial
non_consumption_model_bi2_no_outliers <-
  glm(
    cbind(non_consumption_total, total-non_consumption_total) ~
      food_type,
    data = analysis_file %>% 
      filter(!food_id %in% c("150", "9")) %>% 
      filter(food_type != "meat_based"),
    family = binomial(logit)
  )

# summary
summary(non_consumption_model_bi2_no_outliers)
```

### 3.2.3 Situation independent

I'll continue with non-consumption features.

The model fit is good.
There's a significant difference between meat-based and vegetarian or vegan foods; not surprising, given that these proportions are the inverse of consumption and non-consumption features.

Again, food `150` sticks out as a potential outlier.
```{r situation_independent_binomial}
# binomial
situation_independent_model_bi <-
  glm(
    cbind(situation_independent_total, total-situation_independent_total) ~
      food_type,
    data = analysis_file,
    family = binomial(logit)
  )

# summary
summary(situation_independent_model_bi)

# model diagnostics
plot(situation_independent_model_bi)

# residuals
densityplot(resid(situation_independent_model_bi, scaled = TRUE))

# check formal outliers
arrange_cook(situation_independent_model_bi, "food_id")
```

Like before, I run a model excluding meat-based foods to see whether the difference between vegan and vegetarian is significant.
It is not.

Food `150` again sticks out.
```{r situation_independent_model_no_meat}
# binomial
situation_independent_model_bi2 <-
  glm(
    cbind(situation_independent_total, total-situation_independent_total) ~
      food_type,
    data = analysis_file %>% filter(food_type != "meat_based"),
    family = binomial(logit)
  )

# summary
summary(situation_independent_model_bi2)

# model diagnostics
plot(situation_independent_model_bi2)

# residuals
densityplot(resid(situation_independent_model_bi2, scaled = TRUE))

# check formal outliers
arrange_cook(situation_independent_model_bi2, "food_id")
```

Now I check whether the effects in those two models are robust to outlier exclusion.
They are.
```{r non_situation_independent_model_no_outliers}
# binomial
situation_independent_model_bi_no_outliers <-
  glm(
    cbind(situation_independent_total, total-situation_independent_total) ~
      food_type,
    data = analysis_file %>% 
      filter(!food_id %in% c("150")),
    family = binomial(logit)
  )

# summary
summary(situation_independent_model_bi_no_outliers)

# binomial
situation_independent_model_bi2_no_outliers <-
  glm(
    cbind(situation_independent_total, total-situation_independent_total) ~
      food_type,
    data = analysis_file %>% 
      filter(!food_id %in% c("150")) %>% 
      filter(food_type != "meat_based"),
    family = binomial(logit)
  )

# summary
summary(situation_independent_model_bi2_no_outliers)
```

# 4. Write files
Last, I write the analysis files.
```{r write_files}
write_csv(analysis_file, here("data", "study1", "analysis_file.csv"))
```
