---
title: "Data Analysis Report"
author: "Niklas Johannes"
date: "10/2/2019"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: default
    highlight: default
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      message = FALSE, 
                      warning = FALSE,
                      cache = TRUE)
```

This file explains all data processing and analysis steps for [Project Title].
The RProject has a private library in order to make all steps computationally reproducible.
I use the `renv` package for this.
That means you will need to install the package and might need run the `renv::restore` command, see instructions [here](https://github.com/rstudio/renv).
```{r load_libraries}
# pacman makes it easier to load and install packages
if (!requireNamespace("pacman"))
  install.packages("pacman")

library(pacman)

# load packages
p_load(
  knitr,
  MASS,
  Matrix,
  mgcv,
  Rmisc,
  here,
  DT,
  cowplot,
  pastecs,
  tidyverse
)

# set seed
set.seed(42)

# set theme for ggplot
theme_set(theme_cowplot())
```

Below the custom functions I'll be using throughout the script.
```{r functions}
### FUNCTION 1 ###
# function that transforms feet and inches to cm
feet_inches_to_cm <- 
  function(feet, inches){
    feet_to_cm <- feet * 30.48
    inches_to_cm <- inches * 2.54
    cm <- feet_to_cm + inches_to_cm
    cm <- round(cm, digits = 0)
    
    return(cm)
  }

### FUNCTION 2 ###
# function that transforms stones and pounds to kg
stones_pounds_to_kg <-
  function(pounds, stones=NULL){
    if(missing(stones)){
      pounds_to_kg <- pounds * 0.453592
      kg <- pounds_to_kg
      kg <- round(kg, digits = 0)
      
      return(kg)
    }
    else{
      stones_to_kg <- stones * 6.35029
      pounds_to_kg <- pounds * 0.453592
      kg <- stones_to_kg + pounds_to_kg
      kg <- round(kg, digits = 0)
      
      return(kg)
    }
  }

### FUNCTION 3 ###
# function that gives summary statistics and a densityplot, with different levels of repeated vs. trait-like measures
describe_visualize <- 
  function(df, 
           variable, 
           repeated_measure = FALSE,
           want_summary = FALSE){
    
    variable <- enquo(variable)
    
    # specifies whether the variable we want to plot is a trait-like or repeated measure
    if (repeated_measure == FALSE){
      df <-
        df %>%
        group_by(pp) %>%
        slice(1) %>% 
        ungroup()
    } else {
      df <-
        df
    }
    
    # descriptive stats
    sum_stats <-
      df %>% 
      pull(!! variable) %>% 
      stat.desc()
    
    # plot
    plot <-
      ggplot(df, aes(x = !! variable)) +
        geom_density(color = "darkgrey", fill = "darkgrey") +
        geom_point(aes(x = !! variable, y = 0))
    
    # return the two (if both are wanted)
    if(want_summary == TRUE){
      return(list(kable(sum_stats), plot))
    } else{
      return(plot)
    }
  }

### FUNCTION 4 ###
# function that returns a table for trait-like categorical variables
my_table <-
  function(df, variable){
    variable <- enquo(variable)
    
    df %>% 
      group_by(pp) %>% 
      slice(1) %>% 
      pull(!! variable) %>% 
      table()
  }

### FUNCTION 5 ###
# raincloud plot function from https://github.com/RainCloudPlots/RainCloudPlots/blob/master/tutorial_R/R_rainclouds.R
# Defining the geom_flat_violin function ----
# Note: the below code modifies the
# existing github page by removing a parenthesis in line 50

"%||%" <- function(a, b) {
  if (!is.null(a)) a else b
}

geom_flat_violin <- function(mapping = NULL, data = NULL, stat = "ydensity",
                             position = "dodge", trim = TRUE, scale = "area",
                             show.legend = NA, inherit.aes = TRUE, ...) {
  layer(
    data = data,
    mapping = mapping,
    stat = stat,
    geom = GeomFlatViolin,
    position = position,
    show.legend = show.legend,
    inherit.aes = inherit.aes,
    params = list(
      trim = trim,
      scale = scale,
      ...
    )
  )
}

#' @rdname ggplot2-ggproto
#' @format NULL
#' @usage NULL
#' @export
GeomFlatViolin <-
  ggproto("GeomFlatViolin", Geom,
    setup_data = function(data, params) {
      data$width <- data$width %||%
        params$width %||% (resolution(data$x, FALSE) * 0.9)

      # ymin, ymax, xmin, and xmax define the bounding rectangle for each group
      data %>%
        group_by(group) %>%
        mutate(
          ymin = min(y),
          ymax = max(y),
          xmin = x,
          xmax = x + width / 2
        )
    },

    draw_group = function(data, panel_scales, coord) {
      # Find the points for the line to go all the way around
      data <- transform(data,
        xminv = x,
        xmaxv = x + violinwidth * (xmax - x)
      )

      # Make sure it's sorted properly to draw the outline
      newdata <- rbind(
        plyr::arrange(transform(data, x = xminv), y),
        plyr::arrange(transform(data, x = xmaxv), -y)
      )

      # Close the polygon: set first and last point the same
      # Needed for coord_polar and such
      newdata <- rbind(newdata, newdata[1, ])

      ggplot2:::ggname("geom_flat_violin", GeomPolygon$draw_panel(newdata, panel_scales, coord))
    },

    draw_key = draw_key_polygon,

    default_aes = aes(
      weight = 1, colour = "grey20", fill = "white", size = 0.5,
      alpha = NA, linetype = "solid"
    ),

    required_aes = c("x", "y")
  )

### FUNCTION 6 ###
# creates raincloud plots
rc_plot <-
  function(
    df,
    measurement,
    variable,
    group,
    xlab,
    title,
    facet = NULL
  ) {
    rc_plot <-
    ggplot(
      df %>%
        filter(measure == measurement),
      aes_string(
        x = group,
        y = variable,
        fill = group,
        color = group
      )
    ) +
      geom_flat_violin(position = position_nudge(x = .2,
                                                 y = 0),
                       adjust = 2) +
      geom_point(position = position_jitter(width = .15),
                 size = .10) +
      ylab("Rating (0-100)") +
      xlab(xlab) +
      coord_flip() +
      guides(fill = FALSE,
             color = FALSE) +
      scale_color_brewer(palette = "Dark2") +
      scale_fill_brewer(palette = "Dark2") +
      ggtitle(title)
    
    if(!is.null(facet)){
      rc_plot <-
      rc_plot +
        facet_wrap(facet)
    }
    
    return(rc_plot)
  }

### FUNCTION 6 ###
# creates line plots
line_plot <-
  function(
    df,
    x_group,
    measure,
    group_by
  ) {
    
    measure <- enquo(measure)
    
    ggplot(df,
           aes_string(
             x = x_group,
             y = measure,
             group = group_by,
             color = group_by,
             linetype = group_by
           )
    ) +
      geom_line() +
      geom_point() +
      geom_errorbar(
        aes(
          ymin = !! measure - se,
          ymax = !! measure + se),
        width = .05) +
      scale_color_brewer(palette = "Dark2")
  }
```

# 1. Load and wrangle data
## 1.1 Load data
First, we load the data.
For a codebook, see the [enter file name] file.
Note that the Qualtrics output format is quite the nightmare for importang; found a solution [here](https://stackoverflow.com/questions/50314805/how-to-import-qualtrics-data-in-csv-format-into-r).
```{r load_data}
headers <- read_csv(
  here('data', 'raw_data.csv'),
  col_names = FALSE,
  n_max = 1) %>%
  as.character() # variable names stored in a vector

raw_data <- read_csv(
  here('data', 'raw_data.csv'),
  col_names = headers, # use that name vector here to name variables
  na = "",
  skip = 3 # those are the three rows that contain the variable info
  )

rm(headers) # clear names from workspace
```

The data frame is extremely wide; we have `r ncol(raw_data)` variables.
This has several reasons:

* Qualtrics data are generally in the wide format, so each stimulus gets a column rather than a row
* What label type was assigned to which food type for attractiveness ratings was counterbalanced, such that there were two sets, each containing 40 variables (= 80 total)
* Participants only answered one set, but both sets are contained in the data, meaning that participants will have entries for one set of variables, but only NA for the other set
* Each stimulus was timed, meaning Qualtrics measured four additional variables per stimulus: first click, last click, number of clicks, and after how much time the page was submitted
* This means in addition to the 80 stimulus variables, there are 80 (the two sets) x 4 (timing variables) = `r 80 * 4` variables just for attractiveness ratings (total `r 80 + 80 * 4` attractiveness variables)
* This entire procedure also applies to simulation ratings, doubling the number of stimulus rating variables (`r 80 * 5 * 2` total rating variables)
* The remaining `r ncol(raw_data) - 80 * 5 * 2` are demographic etc. variables

## 1.2 Wrangling
We need to get these data into the long format.
Before that, let's only keep those variables we need and simultaneously give them proper names.
Also, the `response_id` already is a unique identifier, but not easy to read.
I'll add a participant number (`pp`).
Last, because I'm cleaning the raw data, I'll use a new data object: `working_file`
```{r select_and_rename}
working_file <- 
  raw_data %>% 
  select(
    start_date = StartDate,
    end_date = EndDate,
    duration = `Duration (in seconds)`,
    finished = Finished,
    response_id = ResponseId,
    fullfil_criteria = Q3,
    consent = Q8,
    prolific_id = Q9,
    group = Group,
    hungry = Q11_1,
    thirsty = Q11_2,
    desire_instructions_time = `Q13_Page Submit`,
    pb_1_c_attr_1:`mb_20_enh_attr_time_Click Count`, # all attractiveness variables
    simulations_instructions_time = `Q41_Page Submit`,
    pb_1_c_sim_1:`mb_20_enh_sim_time_Click Count`, # all simulation variables
    age = Q19,
    gender = Q20,
    height_choice = Q21,
    height_cm = Q22_1,
    height_feet = Q23_1,
    height_inches = Q23_2,
    weight_choice = Q24,
    weight_kilos = Q25_1,
    weight_stones = Q26_1,
    weight_pounds = Q26_2,
    weight_pounds_only = Q27_1,
    diet = Q28,
    diet_details = Q29,
    meat_per_week = Q30,
    change_diet = Q31_1,
    attitude_meat = attitude_meat_1,
    attitude_vegan = attitude_vegan_1,
    attitude_pb = attitude_pb_1,
    allergies = Q32,
    allergies_details = Q33,
    language_issues = Q34,
    language_issues_details = Q35,
    didnt_like = Q36,
    study_about = Q37,
    technical_issues = Q38,
    -contains("Click"), # omit click count variables
  ) %>%
  mutate(pp = paste0("pp_", row_number())) %>%
  select(# add participant number and set it as first column
    pp,
    everything()
  )
```

Next, I assign the correct variable type.
In addition, I exported the Qualtrics data with numbers as output, so I will reintroduce the factor levels for factor variables.
```{r change_types}
working_file <-
  working_file %>% 
  mutate_at(
    vars(
      pp,
      finished,
      response_id:group,
      gender,
      height_choice,
      weight_choice,
      diet,
      allergies,
      language_issues
    ),
    list(~ as.factor(.))
  ) %>% 
  mutate(
    finished = fct_recode(
      finished,
      no = "0",
      yes = "1"
    ),
    gender = fct_recode(
      gender,
      male = "1",
      female = "2",
      other = "3"
    ),
    diet = fct_recode(
      diet,
      omnivore = "1",
      pescatarian = "2",
      vegetarian = "3",
      vegan = "4",
      other = "5"
    ),
    height_choice = fct_recode(
      height_choice,
      cm = "1",
      feet_inches = "2"
    ),
    weight_choice = fct_recode(
      weight_choice,
      kg = "1",
      stones_pounds = "2",
      pounds_only = "3"
    )
  ) %>% 
  mutate_at(
    vars(
      fullfil_criteria,
      consent,
      allergies,
      language_issues
    ),
    list(
      ~ fct_recode(
        .,
        yes = "1",
        no = "2"
      )
    )
  )
```

Upon inspection, I saw that meat eating frequency (`meat_per_week`) has two non-numerical entries: `1/2` and `less than once`.
I don't want to remove the latter, so I'll convert both to a number (0.5).
```{r recode meat_per_week}
working_file <-
  working_file %>%
  mutate(
    meat_per_week = case_when(
      meat_per_week %in% c("1/2", "less than once") ~ 0.5,
      TRUE ~ as.numeric(meat_per_week)
    )
  )
```

Similarly, there are text entries in `weight_kilos` and `weight_pounds`.
In `weight_kilos` there's a text entry explaining that the respondent doesn't know their weight, so we'll set that to NA.
In `weight_pounds`, the respondent indicated stones, but `"N/A"` for pounds, so we'll set that to 0, assuming the respondent weighed around the indicated weight in stones.
We'll do the same for all those who only provided stones, but no pounds.
```{r recode_weight}
working_file <- 
  working_file %>% 
  mutate(
    weight_kilos = as.numeric(
      na_if(weight_kilos, "I don't lnow unfortuantely and I do not have acces to a set of scales qhilw filling out this survey. I applogise for this, but I was not informed I would need this prior to starting the survey.")
    ),
    weight_pounds = as.numeric(
      na_if(weight_pounds, "N/A")
    ),
    weight_pounds = case_when(
      weight_choice == "stones_pounds" & is.na(weight_pounds) ~ 0,
      TRUE ~ weight_pounds
    )
  )
```

Because the study was conducted in the UK, we also need to transform height and weight to cm and kg, respectively.
```{r transform_height_weight}
working_file <-
  working_file %>% 
  mutate(
    height_cm = case_when(
      height_choice == "cm" ~ height_cm,
      height_choice == "feet_inches" ~ feet_inches_to_cm(height_feet, height_inches)
    ),
    weight_kilos = case_when(
      weight_choice == "kg" ~ weight_kilos,
      weight_choice == "stones_pounds" ~ stones_pounds_to_kg(weight_pounds, weight_stones),
      weight_choice == "pounds_only" ~ stones_pounds_to_kg(weight_pounds_only) 
    )
  )
```

Now that the data are cleaned, I can finally transform them to the long format.
Currently, the measurements of attractiveness and simulations are in the following format: **pb_1_c_attr_1**. The components (separated by underscores) of that format mean:

* **food type**: pb (plant-based) or mb(meat-based)
* **stimulus number**
* **label type**: c (control) or enh (enhanced)
* **measurement/DV**: attr (attractiveness) or sim (simulations)
* meaningless Qualtrics appendix: always `_1`

Let's remove the `_1` at the end of those variable names, and also rename all `Page Submit` appendices from their variable names.
```{r remove_1}
working_file <-
  working_file %>% 
  rename_at(
    vars(
      ends_with("_1"),
    ),
    list(
      ~ str_sub(
        ., 1, str_length(.)-2
      )
    )
  ) %>% 
  rename_at(
    vars(
      ends_with("Page Submit")
    ),
    list(
      ~ str_replace(
        ., "_Page Submit", ""
      )
    )
  )
```

## 1.3 Tidy data
Let's get to turning the data into the long format.
Because we used two sets of stimuli (counterbalancing what stimulus belongs to what food type and label type), half of the participants gave responses to half of the measurement variables; the other half of participant gave responses to the other half.

Therefore, participants will have missing values on those variables that belonged to the other set (i.e., the other counterbalancing condition).
Luckily, the `pivot_longer` function is amazing, so we can drop those measurements per participants with the `values_drop_na` argument.
```{r turn_long}
working_file <- 
  working_file %>% 
  pivot_longer(
    cols = c(contains("pb_"), contains("mb_")),
    names_to = c( # specifict the variables to be formed from the current variable names
      "food_type", 
      "stimulus_no",
      "label_type",
      "measure"
      ),
    values_to = c( # the values, which will be measurement type (attractiveness vs. simulations) and the timer per variable
      "rating", 
      "time"
      ),
    names_sep = "_",
    values_drop_na = TRUE # do not include empty entries due to counterbalancing as rows in the long format
  ) %>%
  
  # give proper variable names, labels, and variable types
  mutate(
    stimulus_no = as.numeric(stimulus_no)
  ) %>% 
  mutate(
    food_type = fct_recode(
      as.factor(food_type),
      meat_based = "mb",
      plant_based = "pb",
    ),
    label_type = fct_recode(
      as.factor(label_type),
      control = "c",
      enhanced = "enh"
    ),
    measure = fct_recode(
      as.factor(measure),
      attractiveness = "attr",
      simulations = "sim"
    )
  ) %>% # arbitrary, but I like to order the variables roughly in the order they were collected
  select(
    pp:simulations_instructions_time,
    food_type:time,
    everything()
  )
```

Alright, the data are in a tidy format.
Below, I show the data of a random participant for illustration.
```{r tidy_data, echo=FALSE}
DT::datatable(
  working_file %>% 
    filter(pp == "pp_100"),
  options = list(
    autoWidth = TRUE,
    scrollY = TRUE,
    scrollX = TRUE, 
    pageLength = 5
  )
  )
```

# 2. Exclusions

## 2.1 Exclude test runs
There are still three test runs left.
They can easily be identified because they do not follow the Prolific ID scheme (i.e., starting with a `5`, less than 20 characters).
We exclude them here.
```{r exclude_test_runs}
# before excluding testruns
length(unique(working_file$pp))

working_file <- 
  working_file %>% 
  filter(
    str_length(
      as.character(prolific_id)
      ) > 20
    )

# # after exclusion
length(unique(working_file$pp))
```

Now exclude those who didn't finish the survey.
```{r exclude_nonfinished}
length(unique(working_file$pp))

working_file <-
  working_file %>% 
  filter(finished == "yes")

length(unique(working_file$pp))
```

Out of experience, Qualtrics isn't very good at determining whether a survey is finished or not.
We double check this:
If indeed all participants gave all ratings, there should be 80 for each of the remaining `r length(unique((working_file$pp)))` participants: 40 attractiveness ratings and 40 simulations ratings.
Furthermore, there should be few `NA`s remaining on any of the ratings.

There are three cases where participants did not report a rating.
I double checked that in the raw data file and that's indeed the case.
Respondents were not forced to give a response (Qualtrics option was "Request Response"), so participants simply did not respond to those three items.
```{r check_total_n}
# does each participant have 80 ratings (i.e., rows)?
working_file %>% 
  group_by(pp) %>% 
  count() %>%
  ungroup() %>% 
  summarize(
    all_there = sum(n == 80)
  )

# compare to sample
length(unique(working_file$pp))

# are there NAs left on the rating or timing variable?
working_file %>% 
  select(rating, time) %>% 
  summarize_all(
    list(~ sum(is.na(.)))
  )

working_file %>% 
  filter(is.na(rating)) %>% 
  DT::datatable(
  .,
  options = list(
    autoWidth = TRUE,
    scrollY = TRUE,
    scrollX = TRUE, 
    pageLength = 3
  )
  )
```

## 2.3 Not fulfilling inclusion criteria
There was a filter question at the beginning of the study asking participants whether they fulfill the inclusion criteria.
All participants indicated they fulfilled the criteria, so no need to exclude anyone.
```{r fulfill_inclusion}
working_file %>% 
  group_by(pp) %>% 
  slice(1) %>% 
  pull(fullfil_criteria) %>% 
  table()
```


## 2.3 Identify rushed responses
In the preregistration, we specified data quality checks: if participants do not comply with the experimental instructions or give (almost) exactly the same response on each trial (i.e., within 1 of 100 scale points).

To identify possibly rushed responses, we inspect the variation of ratings and compare those to the how quickly participants responded.

The variation looks fine, nobody just clicked the same point of the scale repeatedly.
One participant was extremely fast, spending about 1.5 seconds per rating, possibly hinting at randomly clicking through.
```{r response_variation}
# lowest variation of the ratings
working_file %>% 
  group_by(pp) %>% 
  summarize(
    mean = (mean(rating, na.rm = TRUE)),
    sd = sd(rating, na.rm = TRUE)
  ) %>% 
  arrange(sd)

# check response times
time_means <-
  working_file %>% 
  group_by(pp) %>% 
  summarize(
    time_mean = mean(time)
  ) %>% 
  arrange(time_mean)

# inspect the fastest times
head(time_means, n = 10)

# compare to median time
median(working_file$time)

# plot them
time_means %>% 
  ggplot(aes(x = time_mean)) +
  geom_density(color = "darkgrey", fill = "darkgrey") +
  geom_point(aes(x = time_mean, y = 0))

# clear from workspace
rm(time_means)
```

# 3. Describe and visualize

## 3.1 Meta-data
How long did participants spend on the survey?
Median duration is around ~ 13 minutes.
```{r describe_duration}
describe_visualize(
  working_file,
  duration,
  FALSE,
  TRUE
)
```

How long did they spend on the instructions for the attractiveness and simulations, respectively?
Overall not long (~ 10 seconds), but some apparently left the window open for quite some time.
```{r describe_instructions}
describe_visualize(
  working_file,
  desire_instructions_time,
  FALSE,
  TRUE
)

describe_visualize(
  working_file,
  simulations_instructions_time,
  FALSE,
  TRUE
)
```

Were there language issues?
Barely, and the qualitative answers don't give cause for concern.
```{r describe_language}
my_table(working_file, language_issues)

working_file %>% 
  group_by(pp) %>% 
  slice(1) %>% 
  ungroup() %>% 
  filter(language_issues == "yes") %>% 
  pull(language_issues_details)
```

## 3.2 Demographic information
First, I look at hunger and thirst ratings.
Participants seemed to be more thirsty than hungry.
```{r describe_hunger_thirst}
describe_visualize(
  working_file,
  hungry,
  FALSE,
  TRUE
)

describe_visualize(
  working_file,
  thirsty,
  FALSE,
  TRUE
)
```

What's the age range in our sample?
One participant indicated to be `r working_file %>% pull(age) %>% max()` years old.
Probably a typo, but not sure whether it's supposed to be 25 or 59, so I set that value to `NA`.
```{r describe_age}
describe_visualize(
  working_file,
  age,
  FALSE,
  TRUE
)

working_file <-
  working_file %>% 
  mutate(
    age = if_else(age == 259, NA_real_, age)
  )

describe_visualize(
  working_file,
  age,
  FALSE,
  TRUE
)
```

What gender distribution is in our sample?
```{r describe_gender}
my_table(working_file, gender)
```

What's the height distribution?
One participant appears to be giant.
I think this is too unrealistic.
We could think about whether that participant took the survey seriously, but the ratings and duration on instruction look good when inspecting the raw data.
After setting that entry to missing, the rest looks pretty normal.
```{r describe_height}
describe_visualize(
  working_file,
  height_cm,
  FALSE,
  TRUE
)

working_file <-
  working_file %>% 
  mutate(
    height_cm = if_else(height_cm == 290, NA_real_, height_cm)
  )

describe_visualize(
  working_file,
  height_cm,
  FALSE,
  TRUE
)
```

Let's look at the weight.
There's a couple of participants who indicated to weigh less than 20 kilos.
I find that hard to believe and set their weight as missing.
```{r describe_weight}
describe_visualize(
  working_file,
  weight_kilos,
  FALSE,
  TRUE
)

working_file %>% 
  filter(weight_kilos < 20) %>% 
  group_by(pp) %>% 
  slice(1) %>% 
  ungroup() %>% 
  select(pp, contains("weight"))

working_file <-
  working_file %>% 
  mutate(
    weight_kilos = if_else(weight_kilos < 20, NA_real_, weight_kilos)
  )

describe_visualize(
  working_file,
  weight_kilos,
  FALSE,
  TRUE
)
```

Next, some information about their diet.

* participants seem to be divided on whether they're trying to change their diet
* frequent meat eaters
* like meat better than vegan or plant-based foods
```{r describe_diet}
# diet
my_table(working_file, diet)

# how often they eat meat per week
describe_visualize(
  working_file,
  meat_per_week,
  FALSE,
  TRUE
)

# to what extent participants are currently trying to change their diets
describe_visualize(
  working_file,
  change_diet,
  FALSE,
  TRUE
)

# attitudes toward eating meat
describe_visualize(
  working_file,
  attitude_meat,
  FALSE,
  TRUE
)

# attitudes toward vegan food
describe_visualize(
  working_file,
  attitude_vegan,
  FALSE,
  TRUE
)

# attitude toward plant-based food
describe_visualize(
  working_file,
  attitude_pb,
  FALSE,
  TRUE
)

# whether participants have food allergies
my_table(working_file, allergies)
```

## 3.3 Ratings
Next, I visualize the ratings on attractiveness and simulations, respectively.
I'll first visualize and describe them overall, then per factor level (as in two main effects of label type and food type), and then the interaction.

### 3.1 Attractiveness
First, I inspect the overall attractiveness ratings, regardless of label or food type.
```{r attr_overall}
describe_visualize(
  working_file %>% 
    filter(measure == "attractiveness"),
  rating,
  TRUE,
  TRUE
)
```

Next, a raincloud plot with ratings per label type.
Doesn't look like there's much of a difference.
```{r describe_attr_label_type}
rc_plot(
  working_file,
  "attractiveness",
  "rating",
  "label_type",
  "Label Type",
  "Raincloud Plot of Food Attractiveness Ratings"
  )

working_file %>% 
  filter(measure == "attractiveness") %>% 
  group_by(label_type) %>% 
  summarize(
    mean = mean(rating, na.rm = TRUE),
    sd = sd(rating, na.rm = TRUE)
  )
```

Let's inspect the ratings per food type.
People seem to like meat-based labels more.
```{r describe_attr_food_type}
rc_plot(
  working_file,
  "attractiveness",
  "rating",
  "food_type",
  "Food Type",
  "Raincloud Plot of Food Attractiveness Ratings"
  )

working_file %>% 
  filter(measure == "attractiveness") %>% 
  group_by(food_type) %>% 
  summarize(
    mean = mean(rating, na.rm = TRUE),
    sd = sd(rating, na.rm = TRUE)
  )
```

Next, I inspect the interaction of label type and food type for attractiveness ratings.
The raincloud plots are not that easy to read (even if I add means with CIs), so for easier visualization I use a line plot on the aggregated means with within-subject standard error (from the `Rmisc::summarySEwithin` function).
```{r describe_attr_interaction}
rc_plot(
  working_file,
  "attractiveness",
  "rating",
  "label_type",
  "Label Type",
  "Raincloud Plot of Food Attractiveness Ratings",
  "food_type"
  )

# get summary statistics
summary_attr <-
  summarySEwithin(
    data = working_file %>%
      filter(measure == "attractiveness") %>%
      group_by(pp, label_type, food_type) %>%
      summarize(rating = mean(rating, na.rm = TRUE)),
    measurevar = "rating",
    withinvars = c("label_type", "food_type"),
    idvar = "pp"
  )

# have a look at means and SDs
summary_attr

# line graph
line_plot(
  summary_attr,
  "label_type",
  rating,
  "food_type"
)
```

### 3.2 Simulations
First, I inspect the overall simulations ratings, regardless of label or food type.
```{r simulations_overall}
describe_visualize(
  working_file %>% 
    filter(measure == "simulations"),
  rating,
  TRUE,
  TRUE
)
```

Next, a raincloud plot with simulations ratings per label type.
Doesn't look like there's much of a difference.
```{r describe_sim_label_type}
rc_plot(
  working_file,
  "simulations",
  "rating",
  "label_type",
  "Label Type",
  "Raincloud Plot of Food Simulations Ratings"
  )

working_file %>% 
  filter(measure == "simulations") %>% 
  group_by(label_type) %>% 
  summarize(
    mean = mean(rating, na.rm = TRUE),
    sd = sd(rating, na.rm = TRUE)
  )
```

Let's inspect the ratings per food type.
People seem to simulate more with meat-based labels.
```{r describe_sim_food_type}
rc_plot(
  working_file,
  "simulations",
  "rating",
  "food_type",
  "Food Type",
  "Raincloud Plot of Food Simulations Ratings"
  )

working_file %>% 
  filter(measure == "simulations") %>% 
  group_by(food_type) %>% 
  summarize(
    mean = mean(rating, na.rm = TRUE),
    sd = sd(rating, na.rm = TRUE)
  )
```

Next, I inspect the interaction of label type and food type for simulations ratings with rainclouds and line graphs.
```{r describe_sim_interaction}
rc_plot(
  working_file,
  "simulations",
  "rating",
  "label_type",
  "Label Type",
  "Raincloud Plot of Food Attractiveness Ratings",
  "food_type"
  )

# get summary statistics
summary_sim <-
  summarySEwithin(
    data = working_file %>%
      filter(measure == "simulations") %>%
      group_by(pp, label_type, food_type) %>%
      summarize(rating = mean(rating, na.rm = TRUE)),
    measurevar = "rating",
    withinvars = c("label_type", "food_type"),
    idvar = "pp"
  )

# have a look at Ms and SDs
summary_sim

# line graph
line_plot(
  summary_sim,
  "label_type",
  rating,
  "food_type"
)
```

<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;"></div>